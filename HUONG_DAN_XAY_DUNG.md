# üìò H∆Ø·ªöNG D·∫™N X√ÇY D·ª∞NG PROJECT AI YOUTUBE SUMMARIZER

## T·ª´ A ƒë·∫øn Z - H∆∞·ªõng d·∫´n chi ti·∫øt x√¢y d·ª±ng ·ª©ng d·ª•ng t√≥m t·∫Øt video YouTube v·ªõi AI

---

## üìë M·ª•c L·ª•c

1. [T·ªïng Quan Project](#1-t·ªïng-quan-project)
2. [Ki·∫øn Tr√∫c H·ªá Th·ªëng](#2-ki·∫øn-tr√∫c-h·ªá-th·ªëng)
3. [Thi·∫øt L·∫≠p M√¥i Tr∆∞·ªùng](#3-thi·∫øt-l·∫≠p-m√¥i-tr∆∞·ªùng)
4. [X√¢y D·ª±ng T·ª´ng Module](#4-x√¢y-d·ª±ng-t·ª´ng-module)
5. [T√≠ch H·ª£p M√¥ H√¨nh AI](#5-t√≠ch-h·ª£p-m√¥-h√¨nh-ai)
6. [Giao Di·ªán Ng∆∞·ªùi D√πng](#6-giao-di·ªán-ng∆∞·ªùi-d√πng)
7. [Caching v√† T·ªëi ∆Øu](#7-caching-v√†-t·ªëi-∆∞u)
8. [X·ª≠ L√Ω L·ªói v√† Fallback](#8-x·ª≠-l√Ω-l·ªói-v√†-fallback)
9. [Tri·ªÉn Khai ·ª®ng D·ª•ng](#9-tri·ªÉn-khai-·ª©ng-d·ª•ng)

---

## 1. T·ªïng Quan Project

### 1.1 M·ª•c ƒê√≠ch

ƒê√¢y l√† ·ª©ng d·ª•ng web gi√∫p ng∆∞·ªùi d√πng:
- **T√≥m t·∫Øt** n·ªôi dung video YouTube b·∫±ng AI
- **Tr√≤ chuy·ªán** v·ªõi AI v·ªÅ n·ªôi dung video
- **T·∫°o c√¢u h·ªèi tr·∫Øc nghi·ªám** (Quiz) ƒë·ªÉ ki·ªÉm tra ki·∫øn th·ª©c

### 1.2 C√¥ng Ngh·ªá S·ª≠ D·ª•ng

| Th√†nh ph·∫ßn | C√¥ng ngh·ªá | M·ª•c ƒë√≠ch |
|------------|-----------|----------|
| **Frontend** | Streamlit | Framework UI Python |
| **AI/LLM** | Groq API + LLaMA 3.3-70B | X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n |
| **Tr√≠ch xu·∫•t ph·ª• ƒë·ªÅ** | yt-dlp | L·∫•y subtitle t·ª´ YouTube |
| **Parse HTML** | BeautifulSoup4 | X·ª≠ l√Ω HTML |
| **HTTP Requests** | requests | G·ªçi API |
| **Environment** | python-dotenv | Qu·∫£n l√Ω bi·∫øn m√¥i tr∆∞·ªùng |

### 1.3 Lu·ªìng Ho·∫°t ƒê·ªông Ch√≠nh

```
Ng∆∞·ªùi d√πng nh·∫≠p URL video
        ‚Üì
Ki·ªÉm tra URL h·ª£p l·ªá (url_validation.py)
        ‚Üì
Tr√≠ch xu·∫•t ph·ª• ƒë·ªÅ (yt-dlp)
        ‚Üì
G·ª≠i l√™n Groq API v·ªõi model LLaMA 3.3-70B
        ‚Üì
Nh·∫≠n k·∫øt qu·∫£ v√† hi·ªÉn th·ªã
        ‚Üì
Cho ph√©p Chat ho·∫∑c T·∫°o Quiz
```

---

## 2. Ki·∫øn Tr√∫c H·ªá Th·ªëng

### 2.1 C·∫•u Tr√∫c Th∆∞ M·ª•c

```
ai-youtube-summarizer/
‚îÇ
‚îú‚îÄ‚îÄ üìÑ app.py                      # File ch√≠nh - ƒëi·ªÅu ph·ªëi to√†n b·ªô ·ª©ng d·ª•ng
‚îú‚îÄ‚îÄ üìÑ requirements.txt            # Danh s√°ch th∆∞ vi·ªán c·∫ßn c√†i
‚îú‚îÄ‚îÄ üìÑ .env                        # Bi·∫øn m√¥i tr∆∞·ªùng (API Key)
‚îÇ
‚îú‚îÄ‚îÄ üìÇ components/                 # C√°c component UI
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ __init__.py            # ƒê√°nh d·∫•u l√† Python package
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ chatbot.py             # Module chat AI
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ quiz_display.py        # Module hi·ªÉn th·ªã quiz
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ intro.py               # M√†n h√¨nh gi·ªõi thi·ªáu
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ sidebar.py             # Thanh sidebar (nh·∫≠p API Key)
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ url_validation.py      # Ki·ªÉm tra URL YouTube
‚îÇ
‚îú‚îÄ‚îÄ üìÇ utils/                      # C√°c h√†m x·ª≠ l√Ω logic
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ summarization.py       # T·∫°o b·∫£n t√≥m t·∫Øt v·ªõi AI
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ quiz_generator.py      # T·∫°o c√¢u h·ªèi tr·∫Øc nghi·ªám
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ youtube_transcript.py  # Tr√≠ch xu·∫•t ph·ª• ƒë·ªÅ (n·∫øu c√≥)
‚îÇ
‚îú‚îÄ‚îÄ üìÇ config/                     # C·∫•u h√¨nh
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ settings.py            # Load API key
‚îÇ
‚îî‚îÄ‚îÄ üìÇ styles/                     # CSS styles
    ‚îú‚îÄ‚îÄ üìÑ __init__.py
    ‚îî‚îÄ‚îÄ üìÑ styles.py              # Custom CSS cho UI
```

### 2.2 S∆° ƒê·ªì T∆∞∆°ng T√°c Gi·ªØa C√°c Module

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ           app.py                ‚îÇ
                    ‚îÇ     (ƒêi·ªÅu ph·ªëi ch√≠nh)           ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                         ‚îÇ                         ‚îÇ
        ‚ñº                         ‚ñº                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ components/   ‚îÇ       ‚îÇ    utils/     ‚îÇ       ‚îÇ   config/     ‚îÇ
‚îÇ - sidebar.py  ‚îÇ       ‚îÇ - summarize   ‚îÇ       ‚îÇ - settings.py ‚îÇ
‚îÇ - chatbot.py  ‚îÇ       ‚îÇ - quiz_gen    ‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ - quiz_disp   ‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ - url_valid   ‚îÇ               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚ñº
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                        ‚îÇ   Groq API    ‚îÇ
                        ‚îÇ (LLaMA 3.3)   ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 3. Thi·∫øt L·∫≠p M√¥i Tr∆∞·ªùng

### 3.1 B∆∞·ªõc 1: T·∫°o Th∆∞ M·ª•c Project

```bash
mkdir ai-youtube-summarizer
cd ai-youtube-summarizer
```

### 3.2 B∆∞·ªõc 2: T·∫°o M√¥i Tr∆∞·ªùng ·∫¢o Python

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

**T·∫°i sao d√πng m√¥i tr∆∞·ªùng ·∫£o?**
- C√°ch ly c√°c th∆∞ vi·ªán ri√™ng cho t·ª´ng project
- Tr√°nh xung ƒë·ªôt phi√™n b·∫£n gi·ªØa c√°c project
- D·ªÖ d√†ng qu·∫£n l√Ω v√† t√°i t·∫°o m√¥i tr∆∞·ªùng

### 3.3 B∆∞·ªõc 3: T·∫°o File requirements.txt

```txt
yt-dlp
streamlit
groq
python-dotenv
pathlib
pyperclip
beautifulsoup4
requests
```

**Gi·∫£i th√≠ch t·ª´ng th∆∞ vi·ªán:**

| Th∆∞ vi·ªán | M·ª•c ƒë√≠ch |
|----------|----------|
| `yt-dlp` | Tr√≠ch xu·∫•t ph·ª• ƒë·ªÅ v√† th√¥ng tin video YouTube |
| `streamlit` | Framework t·∫°o giao di·ªán web nhanh ch√≥ng |
| `groq` | Client ƒë·ªÉ g·ªçi Groq API (ch·∫°y model LLaMA) |
| `python-dotenv` | ƒê·ªçc bi·∫øn m√¥i tr∆∞·ªùng t·ª´ file .env |
| `pathlib` | X·ª≠ l√Ω ƒë∆∞·ªùng d·∫´n file |
| `pyperclip` | Copy text v√†o clipboard |
| `beautifulsoup4` | Parse HTML ƒë·ªÉ l·∫•y ti√™u ƒë·ªÅ video |
| `requests` | G·ª≠i HTTP requests |

### 3.4 B∆∞·ªõc 4: C√†i ƒê·∫∑t Th∆∞ Vi·ªán

```bash
pip install -r requirements.txt
```

### 3.5 B∆∞·ªõc 5: T·∫°o File .env

```env
GROQ_API_KEY=gsk_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

**L·∫•y API Key t·ª´ ƒë√¢u?**
1. Truy c·∫≠p https://console.groq.com/keys
2. ƒêƒÉng k√Ω t√†i kho·∫£n (mi·ªÖn ph√≠)
3. T·∫°o API Key m·ªõi
4. Copy v√† d√°n v√†o file .env

‚ö†Ô∏è **L∆∞u √Ω b·∫£o m·∫≠t:** Kh√¥ng commit file .env l√™n Git!

---

## 4. X√¢y D·ª±ng T·ª´ng Module

### 4.1 Module Config (config/settings.py)

**M·ª•c ƒë√≠ch:** Load API key t·ª´ bi·∫øn m√¥i tr∆∞·ªùng

```python
import os
from dotenv import load_dotenv

def load_api_key():
    """Load API key t·ª´ file .env ho·∫∑c bi·∫øn m√¥i tr∆∞·ªùng."""
    load_dotenv()  # ƒê·ªçc file .env
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        raise ValueError("API Key not found. Please set it in your environment.")
    return api_key
```

**Gi·∫£i th√≠ch:**
- `load_dotenv()` ƒë·ªçc t·∫•t c·∫£ bi·∫øn trong file .env v√† load v√†o environment
- `os.getenv("GROQ_API_KEY")` l·∫•y gi√° tr·ªã c·ªßa bi·∫øn GROQ_API_KEY
- N·∫øu kh√¥ng t√¨m th·∫•y ‚Üí raise l·ªói ƒë·ªÉ ng∆∞·ªùi d√πng bi·∫øt

---

### 4.2 Module Ki·ªÉm Tra URL (components/url_validation.py)

**M·ª•c ƒë√≠ch:** X√°c th·ª±c URL c√≥ ph·∫£i YouTube hay kh√¥ng

```python
import re

def is_valid_youtube_url(url):
    """
    Ki·ªÉm tra URL c√≥ ph·∫£i link YouTube h·ª£p l·ªá kh√¥ng.
    
    H·ªó tr·ª£ c√°c format:
    - https://www.youtube.com/watch?v=VIDEO_ID
    - https://youtu.be/VIDEO_ID
    - https://youtube.com/shorts/VIDEO_ID
    """
    youtube_patterns = [
        r'(https?://)?(www\.)?youtube\.com/watch\?v=[\w-]+',
        r'(https?://)?(www\.)?youtu\.be/[\w-]+',
        r'(https?://)?(www\.)?youtube\.com/shorts/[\w-]+'
    ]
    
    for pattern in youtube_patterns:
        if re.match(pattern, url):
            return True
    return False
```

**Gi·∫£i th√≠ch:**
- S·ª≠ d·ª•ng regex (Regular Expression) ƒë·ªÉ match pattern URL
- H·ªó tr·ª£ nhi·ªÅu format URL kh√°c nhau c·ªßa YouTube
- Tr·∫£ v·ªÅ `True/False` ƒë·ªÉ x√°c ƒë·ªãnh URL h·ª£p l·ªá

---

### 4.3 Module T√≥m T·∫Øt (utils/summarization.py)

**M·ª•c ƒë√≠ch:** G·ªçi AI ƒë·ªÉ t√≥m t·∫Øt n·ªôi dung video

```python
from groq import Groq
import streamlit as st

# Prompt template cho vi·ªác t√≥m t·∫Øt
prompt_template = """Summarize the given YouTube video transcript in bullet points, 
focusing only on the most important information. The summary should be clear, 
concise, and within 250 words. Please summarize it in {language}."""

# Gi·ªõi h·∫°n ƒë·ªô d√†i transcript ƒë·ªÉ tr√°nh v∆∞·ª£t token limit
MAX_TRANSCRIPT_LENGTH = 15000  # ~4000 tokens

def truncate_transcript(transcript_text, max_length=MAX_TRANSCRIPT_LENGTH):
    """C·∫Øt transcript n·∫øu qu√° d√†i ƒë·ªÉ tr√°nh v∆∞·ª£t token limit c·ªßa API."""
    if len(transcript_text) > max_length:
        truncated = transcript_text[:max_length]
        # T√¨m v·ªã tr√≠ k·∫øt th√∫c c√¢u g·∫ßn nh·∫•t
        last_period = truncated.rfind('.')
        if last_period > max_length * 0.8:
            truncated = truncated[:last_period + 1]
        return truncated + "\n\n[Transcript ƒë√£ ƒë∆∞·ª£c r√∫t g·ªçn do qu√° d√†i]"
    return transcript_text

def generate_llama3_content(client, transcript_text, prompt, language):
    """T·∫°o b·∫£n t√≥m t·∫Øt s·ª≠ d·ª•ng Groq API."""
    formatted_prompt = prompt.format(language=language)
    truncated_transcript = truncate_transcript(transcript_text)
    
    try:
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",  # Model LLaMA 3.3 70B
            messages=[
                {
                    "role": "user",
                    "content": formatted_prompt + "\n\nTranscript:\n" + truncated_transcript
                }
            ],
            temperature=0.7,    # ƒê·ªô s√°ng t·∫°o (0-1)
            max_tokens=1024,    # S·ªë token t·ªëi ƒëa cho output
            top_p=1,
            stream=True,        # Streaming response
        )
        
        # Nh·∫≠n response theo t·ª´ng chunk (streaming)
        summary = ""
        for chunk in completion:
            if chunk.choices[0].delta.content:
                summary += chunk.choices[0].delta.content
        
        return summary
        
    except Exception as e:
        # X·ª≠ l√Ω l·ªói v√† th·ª≠ model d·ª± ph√≤ng
        error_msg = str(e)
        if "rate_limit" in error_msg.lower():
            st.error("‚ö†Ô∏è ƒê√£ v∆∞·ª£t qu√° gi·ªõi h·∫°n API. Vui l√≤ng ƒë·ª£i v√†i ph√∫t.")
        elif "model" in error_msg.lower():
            return generate_with_fallback_model(client, formatted_prompt, truncated_transcript)
        return None
```

**Gi·∫£i th√≠ch chi ti·∫øt:**

1. **Prompt Template:**
   - Template ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ AI t√≥m t·∫Øt theo d·∫°ng bullet points
   - Gi·ªõi h·∫°n 250 t·ª´ ƒë·ªÉ output g·ªçn g√†ng
   - H·ªó tr·ª£ ƒëa ng√¥n ng·ªØ qua bi·∫øn `{language}`

2. **Truncate Transcript:**
   - API c√≥ gi·ªõi h·∫°n token (~4000 tokens cho input)
   - C·∫Øt transcript th√¥ng minh t·∫°i cu·ªëi c√¢u ƒë·ªÉ kh√¥ng m·∫•t ng·ªØ nghƒ©a

3. **Streaming Response:**
   - `stream=True` cho ph√©p nh·∫≠n response theo t·ª´ng ph·∫ßn
   - Gi√∫p hi·ªÉn th·ªã k·∫øt qu·∫£ nhanh h∆°n, UX t·ªët h∆°n

4. **Parameters quan tr·ªçng:**
   - `temperature=0.7`: C√¢n b·∫±ng gi·ªØa s√°ng t·∫°o v√† ch√≠nh x√°c
   - `max_tokens=1024`: ƒê·ªß d√†i cho b·∫£n t√≥m t·∫Øt chi ti·∫øt

---

### 4.4 Module Quiz Generator (utils/quiz_generator.py)

**M·ª•c ƒë√≠ch:** T·∫°o c√¢u h·ªèi tr·∫Øc nghi·ªám t·ª´ n·ªôi dung video

```python
import json
import re
import streamlit as st

# Prompt template ƒë·ªÉ t·∫°o quiz
QUIZ_PROMPT_TEMPLATE = """D·ª±a tr√™n n·ªôi dung t√≥m t·∫Øt video sau:

{summary}

H√£y t·∫°o {num_questions} c√¢u h·ªèi tr·∫Øc nghi·ªám b·∫±ng ti·∫øng {language} v·ªõi ƒë·ªô kh√≥ {difficulty}.

Y√äU C·∫¶U:
1. M·ªói c√¢u h·ªèi c√≥ 4 ƒë√°p √°n A, B, C, D
2. Ch·ªâ c√≥ 1 ƒë√°p √°n ƒë√∫ng
3. C√¢u h·ªèi ph·∫£i li√™n quan tr·ª±c ti·∫øp ƒë·∫øn n·ªôi dung video
4. Gi·∫£i th√≠ch ng·∫Øn g·ªçn t·∫°i sao ƒë√°p √°n ƒë√≥ ƒë√∫ng

QUAN TR·ªåNG: Tr·∫£ v·ªÅ CH√çNH X√ÅC theo format JSON sau:
{{
    "questions": [
        {{
            "id": 1,
            "question": "N·ªôi dung c√¢u h·ªèi?",
            "options": ["A. ƒê√°p √°n A", "B. ƒê√°p √°n B", "C. ƒê√°p √°n C", "D. ƒê√°p √°n D"],
            "correct": "A",
            "explanation": "Gi·∫£i th√≠ch ng·∫Øn g·ªçn"
        }}
    ]
}}
"""

def generate_quiz(client, summary: str, num_questions: int = 5, 
                  difficulty: str = "medium", language: str = "Vi·ªát") -> dict:
    """
    T·∫°o quiz t·ª´ n·ªôi dung t√≥m t·∫Øt video.
    """
    prompt = QUIZ_PROMPT_TEMPLATE.format(
        summary=summary,
        num_questions=num_questions,
        difficulty=difficulty,
        language=language
    )
    
    try:
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {
                    "role": "system",
                    "content": "B·∫°n l√† chuy√™n gia t·∫°o c√¢u h·ªèi tr·∫Øc nghi·ªám gi√°o d·ª•c. Lu√¥n tr·∫£ v·ªÅ JSON h·ª£p l·ªá."
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            temperature=0.7,
            max_tokens=4096,  # C·∫ßn nhi·ªÅu token h∆°n cho quiz d√†i
        )
        
        response_text = completion.choices[0].message.content
        quiz_data = parse_quiz_response(response_text)
        
        return quiz_data
        
    except Exception as e:
        st.error(f"‚ùå L·ªói t·∫°o quiz: {str(e)}")
        return None


def parse_quiz_response(response_text: str) -> dict:
    """
    Parse JSON t·ª´ response c·ªßa AI.
    X·ª≠ l√Ω c√°c tr∆∞·ªùng h·ª£p AI tr·∫£ v·ªÅ text k√®m JSON.
    """
    try:
        return json.loads(response_text)
    except json.JSONDecodeError:
        pass
    
    # T√¨m JSON trong response b·∫±ng regex
    json_patterns = [
        r'\{[\s\S]*"questions"[\s\S]*\}',  # T√¨m object c√≥ "questions"
        r'```json\s*([\s\S]*?)\s*```',      # T√¨m trong code block
    ]
    
    for pattern in json_patterns:
        matches = re.findall(pattern, response_text)
        for match in matches:
            try:
                return json.loads(match)
            except json.JSONDecodeError:
                continue
    
    return None
```

**Gi·∫£i th√≠ch chi ti·∫øt:**

1. **System Prompt:**
   - ƒê·ªãnh nghƒ©a AI l√† "chuy√™n gia t·∫°o c√¢u h·ªèi"
   - Y√™u c·∫ßu tr·∫£ v·ªÅ JSON h·ª£p l·ªá

2. **Format JSON nghi√™m ng·∫∑t:**
   - M·ªói c√¢u h·ªèi c√≥: id, question, options, correct, explanation
   - 4 ƒë√°p √°n A, B, C, D
   - C√≥ gi·∫£i th√≠ch cho t·ª´ng c√¢u

3. **Parse Response:**
   - AI ƒë√¥i khi tr·∫£ v·ªÅ text + JSON
   - S·ª≠ d·ª•ng regex ƒë·ªÉ t√¨m v√† extract JSON
   - Fallback n·∫øu parse th·∫•t b·∫°i

---

### 4.5 Module Chatbot (components/chatbot.py)

**M·ª•c ƒë√≠ch:** Chat AI v·ªÅ n·ªôi dung video

```python
import streamlit as st
from groq import Groq

# System prompt cho chatbot
CHATBOT_SYSTEM_PROMPT = """B·∫°n l√† tr·ª£ l√Ω AI th√¥ng minh, th√¢n thi·ªán v√† h·ªØu √≠ch. 
B·∫°n c√≥ nhi·ªám v·ª• gi√∫p ng∆∞·ªùi d√πng hi·ªÉu s√¢u h∆°n v·ªÅ n·ªôi dung video YouTube.

NGUY√äN T·∫ÆC:
1. Tr·∫£ l·ªùi d·ª±a tr√™n n·ªôi dung video ƒë√£ ƒë∆∞·ª£c t√≥m t·∫Øt
2. N·∫øu c√¢u h·ªèi n·∫±m ngo√†i n·ªôi dung video, th√¥ng b√°o l·ªãch s·ª±
3. S·ª≠ d·ª•ng ng√¥n ng·ªØ d·ªÖ hi·ªÉu, th√¢n thi·ªán
4. C√≥ th·ªÉ ƒë∆∞a ra v√≠ d·ª• minh h·ªça khi c·∫ßn
5. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát

N·ªòI DUNG VIDEO ƒê√É T√ìM T·∫ÆT:
{summary}
"""

def generate_chatbot_response(client, user_question, use_context=True):
    """
    T·∫°o c√¢u tr·∫£ l·ªùi t·ª´ chatbot.
    """
    summary = st.session_state.get('follow_up_summary', "")
    
    if not summary and use_context:
        return "‚ö†Ô∏è Ch∆∞a c√≥ b·∫£n t√≥m t·∫Øt video. Vui l√≤ng t·∫°o b·∫£n t√≥m t·∫Øt tr∆∞·ªõc!"
    
    # Build messages v·ªõi conversation history
    messages = []
    
    # System message v·ªõi context t·ª´ summary
    if use_context and summary:
        system_content = CHATBOT_SYSTEM_PROMPT.format(summary=summary)
        messages.append({"role": "system", "content": system_content})
    
    # Th√™m l·ªãch s·ª≠ chat (gi·ªØ 10 tin nh·∫Øn g·∫ßn nh·∫•t)
    history = st.session_state.get('chat_messages', [])[-10:]
    for msg in history:
        messages.append({"role": msg["role"], "content": msg["content"]})
    
    # Th√™m c√¢u h·ªèi hi·ªán t·∫°i
    messages.append({"role": "user", "content": user_question})
    
    try:
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages,
            temperature=0.7,
            max_tokens=1500,
            stream=True,
        )
        
        response = ""
        for chunk in completion:
            if chunk.choices[0].delta.content:
                response += chunk.choices[0].delta.content
        
        return response
        
    except Exception as e:
        return f"‚ùå L·ªói: {str(e)}"
```

**Gi·∫£i th√≠ch:**

1. **Context-Aware:**
   - Chatbot bi·∫øt n·ªôi dung video th√¥ng qua summary
   - Tr·∫£ l·ªùi d·ª±a tr√™n ng·ªØ c·∫£nh c·ª• th·ªÉ

2. **Conversation History:**
   - L∆∞u l·ªãch s·ª≠ 10 tin nh·∫Øn g·∫ßn nh·∫•t
   - Gi√∫p AI hi·ªÉu ng·ªØ c·∫£nh cu·ªôc h·ªôi tho·∫°i

3. **Role-based Messages:**
   - `system`: ƒê·ªãnh nghƒ©a behavior c·ªßa AI
   - `user`: Tin nh·∫Øn t·ª´ ng∆∞·ªùi d√πng
   - `assistant`: C√¢u tr·∫£ l·ªùi c·ªßa AI

---

## 5. T√≠ch H·ª£p M√¥ H√¨nh AI

### 5.1 C√°c Model S·ª≠ D·ª•ng

| Model | M·ª•c ƒë√≠ch | ƒê·∫∑c ƒëi·ªÉm |
|-------|----------|----------|
| **llama-3.3-70b-versatile** | Model ch√≠nh | 70 t·ª∑ parameters, ƒëa nƒÉng |
| **llama-3.1-70b-versatile** | Fallback 1 | Phi√™n b·∫£n tr∆∞·ªõc, ·ªïn ƒë·ªãnh |
| **llama-3.1-8b-instant** | Fallback 2 | Nh·∫π, nhanh, cho task ƒë∆°n gi·∫£n |
| **mixtral-8x7b-32768** | Fallback 3 | Model backup khi c·∫ßn |

### 5.2 C∆° Ch·∫ø Chuy·ªÉn ƒê·ªïi Model (Fallback)

```python
def generate_with_fallback_model(client, prompt, transcript):
    """S·ª≠ d·ª•ng model d·ª± ph√≤ng n·∫øu model ch√≠nh kh√¥ng kh·∫£ d·ª•ng."""
    fallback_models = [
        "llama-3.1-70b-versatile",   # Fallback 1
        "llama-3.1-8b-instant",       # Fallback 2 (nhanh h∆°n)
        "mixtral-8x7b-32768"          # Fallback 3
    ]
    
    for model in fallback_models:
        try:
            completion = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt + "\n\nTranscript:\n" + transcript}],
                temperature=0.7,
                max_tokens=1024,
                stream=True,
            )
            
            summary = ""
            for chunk in completion:
                if chunk.choices[0].delta.content:
                    summary += chunk.choices[0].delta.content
            
            st.success(f"‚úÖ ƒê√£ s·ª≠ d·ª•ng model d·ª± ph√≤ng: {model}")
            return summary
            
        except Exception:
            continue  # Th·ª≠ model ti·∫øp theo
    
    st.error("‚ùå T·∫•t c·∫£ c√°c model ƒë·ªÅu kh√¥ng kh·∫£ d·ª•ng.")
    return None
```

**T·∫°i sao c·∫ßn Fallback?**
- API c√≥ th·ªÉ b·ªã qu√° t·∫£i (rate limit)
- Model c·ª• th·ªÉ c√≥ th·ªÉ ƒëang b·∫£o tr√¨
- ƒê·∫£m b·∫£o ·ª©ng d·ª•ng lu√¥n ho·∫°t ƒë·ªông

### 5.3 C√°ch G·ªçi API Groq

```python
from groq import Groq

# Kh·ªüi t·∫°o client
client = Groq(api_key="your_api_key")

# G·ªçi API
completion = client.chat.completions.create(
    model="llama-3.3-70b-versatile",
    messages=[
        {"role": "system", "content": "B·∫°n l√† tr·ª£ l√Ω AI h·ªØu √≠ch."},
        {"role": "user", "content": "Xin ch√†o!"}
    ],
    temperature=0.7,      # 0 = ch√≠nh x√°c, 1 = s√°ng t·∫°o
    max_tokens=1024,      # ƒê·ªô d√†i t·ªëi ƒëa output
    top_p=1,              # Nucleus sampling
    stream=True,          # Nh·∫≠n response theo chunk
)
```

### 5.4 Gi·∫£i Th√≠ch C√°c Tham S·ªë

| Tham s·ªë | Gi√° tr·ªã | √ù nghƒ©a |
|---------|---------|---------|
| `temperature` | 0.0 - 1.0 | ƒê·ªô s√°ng t·∫°o. 0 = deterministic, 1 = random |
| `max_tokens` | int | S·ªë token t·ªëi ƒëa cho output |
| `top_p` | 0.0 - 1.0 | Nucleus sampling threshold |
| `stream` | bool | True = nh·∫≠n response t·ª´ng ph·∫ßn |
| `stop` | list | Chu·ªói ƒë·ªÉ d·ª´ng generate |

---

## 6. Giao Di·ªán Ng∆∞·ªùi D√πng

### 6.1 C·∫•u Tr√∫c App Ch√≠nh (app.py)

```python
import streamlit as st

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="AI YouTube Summarizer",
    page_icon="üé¨",
    initial_sidebar_state="expanded",
    layout="wide"
)

# Session State - L∆∞u tr·∫°ng th√°i qua c√°c l·∫ßn rerun
def init_session_state():
    defaults = {
        "accepted_terms": False,       # ƒê√£ ƒë·ªìng √Ω ƒëi·ªÅu kho·∫£n
        "cached_summary": None,        # B·∫£n t√≥m t·∫Øt ƒë√£ cache
        "quiz_data": None,             # D·ªØ li·ªáu quiz
        "chat_messages": [],           # L·ªãch s·ª≠ chat
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

init_session_state()

# Layout ch√≠nh v·ªõi Tabs
if st.session_state.accepted_terms and client:
    # Input URL
    youtube_link = st.text_input("üîó Nh·∫≠p URL Video YouTube:")
    
    if youtube_link:
        # Hi·ªÉn th·ªã video
        st.video(youtube_link)
        
        # 3 Tabs
        tab1, tab2, tab3 = st.tabs([
            "üìù T√≥m T·∫Øt",
            "üí¨ Tr√≤ Chuy·ªán", 
            "üìö Quiz H·ªçc T·∫≠p"
        ])
        
        with tab1:
            display_summary_tab(client, youtube_link, selected_language)
        
        with tab2:
            display_chat_enhanced(client)
        
        with tab3:
            display_quiz_generator(client)
```

### 6.2 Session State

**Session State l√† g√¨?**
- Streamlit rerun to√†n b·ªô script m·ªói khi c√≥ interaction
- Session State l∆∞u gi·ªØ d·ªØ li·ªáu qua c√°c l·∫ßn rerun
- Gi·ªëng nh∆∞ "memory" c·ªßa ·ª©ng d·ª•ng

```python
# L∆∞u v√†o session state
st.session_state.cached_summary = "N·ªôi dung t√≥m t·∫Øt..."

# ƒê·ªçc t·ª´ session state
summary = st.session_state.get('cached_summary', None)

# Ki·ªÉm tra t·ªìn t·∫°i
if 'cached_summary' in st.session_state:
    print("ƒê√£ c√≥ summary")
```

### 6.3 C√°c Component UI

**Sidebar (thanh b√™n):**
```python
with st.sidebar:
    st.image("logo.png")
    api_key = st.text_input("üîë API Key:", type="password")
    st.divider()
    st.info("Nh·∫≠p Groq API Key ƒë·ªÉ s·ª≠ d·ª•ng")
```

**Text Input v·ªõi placeholder:**
```python
youtube_link = st.text_input(
    "üîó Nh·∫≠p URL Video YouTube:",
    placeholder="https://www.youtube.com/watch?v=example",
    label_visibility="visible"
)
```

**Button v·ªõi tr·∫°ng th√°i:**
```python
if st.button("üìì T·∫°o B·∫£n T√≥m T·∫Øt", type="primary", use_container_width=True):
    with st.spinner("üîÑ ƒêang x·ª≠ l√Ω..."):
        # Logic x·ª≠ l√Ω
        pass
    st.success("‚úÖ Ho√†n th√†nh!")
```

**Radio buttons cho quiz:**
```python
selected = st.radio(
    "Ch·ªçn ƒë√°p √°n:",
    options=["A. ƒê√°p √°n 1", "B. ƒê√°p √°n 2", "C. ƒê√°p √°n 3", "D. ƒê√°p √°n 4"],
    index=None,  # Kh√¥ng ch·ªçn m·∫∑c ƒë·ªãnh
)
```

---

## 7. Caching v√† T·ªëi ∆Øu

### 7.1 Streamlit Caching

```python
@st.cache_data(show_spinner=True)
def get_summary(_client, transcript_text, language, video_id):
    """
    Cache b·∫£n t√≥m t·∫Øt ƒë·ªÉ tr√°nh g·ªçi API l·∫°i.
    
    _client c√≥ d·∫•u _ ƒë·∫ßu ƒë·ªÉ kh√¥ng ƒë∆∞·ª£c hash (unhashable object)
    """
    cache_key = f"summary_{video_id}_{language}"
    
    # Ki·ªÉm tra cache trong session state
    if cache_key in st.session_state:
        return st.session_state[cache_key]
    
    # T·∫°o m·ªõi v√† cache
    summary = generate_llama3_content(_client, transcript_text, prompt_template, language)
    st.session_state[cache_key] = summary
    
    return summary
```

**Gi·∫£i th√≠ch:**
- `@st.cache_data`: Decorator ƒë·ªÉ cache k·∫øt qu·∫£ function
- `_client`: D·∫•u `_` ƒë·∫ßu cho Streamlit bi·∫øt kh√¥ng hash parameter n√†y
- Ti·∫øt ki·ªám API calls khi user refresh trang

### 7.2 Cache Expiry

```python
current_time = time.time()
cache_expiry = 3600  # 1 gi·ªù

need_regenerate = (
    st.session_state.cached_summary is None or
    current_time - st.session_state.cached_summary_timestamp > cache_expiry or
    st.session_state.current_video_url != youtube_link
)

if need_regenerate:
    # T·∫°o m·ªõi
    pass
else:
    # D√πng cache
    pass
```

---

## 8. X·ª≠ L√Ω L·ªói v√† Fallback

### 8.1 C√°c L·ªói Th∆∞·ªùng G·∫∑p

| L·ªói | Nguy√™n nh√¢n | X·ª≠ l√Ω |
|-----|-------------|-------|
| `rate_limit` | V∆∞·ª£t quota API | Ch·ªù v√† retry |
| `invalid_api_key` | API key sai | Th√¥ng b√°o user |
| `model_not_available` | Model ƒëang b·∫£o tr√¨ | Chuy·ªÉn fallback model |
| `token_limit` | Input qu√° d√†i | Truncate transcript |

### 8.2 Error Handling Pattern

```python
try:
    # G·ªçi API
    completion = client.chat.completions.create(...)
    
except Exception as e:
    error_msg = str(e).lower()
    
    if "rate_limit" in error_msg:
        st.warning("‚ö†Ô∏è ƒê√£ v∆∞·ª£t gi·ªõi h·∫°n. ƒê·ª£i 1 ph√∫t...")
        time.sleep(60)
        # Retry
        
    elif "invalid_api_key" in error_msg:
        st.error("‚ùå API Key kh√¥ng h·ª£p l·ªá!")
        st.stop()  # D·ª´ng ·ª©ng d·ª•ng
        
    elif "model" in error_msg:
        # Th·ª≠ fallback model
        return generate_with_fallback_model(...)
        
    else:
        st.error(f"‚ùå L·ªói kh√¥ng x√°c ƒë·ªãnh: {error_msg}")
        return None
```

### 8.3 Graceful Degradation

```python
def generate_quiz_fallback(client, summary, num_questions, difficulty, language):
    """Fallback khi kh√¥ng parse ƒë∆∞·ª£c JSON t·ª´ AI."""
    
    # Th·ª≠ v·ªõi prompt ƒë∆°n gi·∫£n h∆°n
    simple_prompt = f"T·∫°o {num_questions} c√¢u h·ªèi. Ch·ªâ tr·∫£ v·ªÅ JSON."
    
    try:
        # Th·ª≠ model nh·∫π h∆°n
        completion = client.chat.completions.create(
            model="llama-3.1-8b-instant",  # Model nhanh h∆°n
            messages=[{"role": "user", "content": simple_prompt}],
            temperature=0.5,  # √çt random h∆°n
        )
        return parse_quiz_response(completion.choices[0].message.content)
        
    except Exception:
        # Tr·∫£ v·ªÅ quiz m·∫´u n·∫øu th·∫•t b·∫°i ho√†n to√†n
        return {
            "questions": [{
                "id": 1,
                "question": "Kh√¥ng th·ªÉ t·∫°o quiz. Vui l√≤ng th·ª≠ l·∫°i.",
                "options": ["A. Th·ª≠ l·∫°i", "B. Th·ª≠ l·∫°i", "C. Th·ª≠ l·∫°i", "D. Th·ª≠ l·∫°i"],
                "correct": "A",
                "explanation": "Vui l√≤ng refresh trang."
            }]
        }
```

---

## 9. Tri·ªÉn Khai ·ª®ng D·ª•ng

### 9.1 Ch·∫°y Local

```bash
# K√≠ch ho·∫°t m√¥i tr∆∞·ªùng ·∫£o
venv\Scripts\activate  # Windows
source venv/bin/activate  # macOS/Linux

# Ch·∫°y ·ª©ng d·ª•ng
python -m streamlit run app.py

# M·ªü tr√¨nh duy·ªát
# http://localhost:8501
```

### 9.2 Deploy l√™n Streamlit Cloud

1. **Push code l√™n GitHub**
```bash
git init
git add .
git commit -m "Initial commit"
git remote add origin https://github.com/username/repo.git
git push -u origin main
```

2. **C·∫•u h√¨nh .streamlit/config.toml**
```toml
[server]
headless = true
port = 8501
enableCORS = false

[theme]
primaryColor = "#FF4B4B"
backgroundColor = "#0E1117"
secondaryBackgroundColor = "#262730"
textColor = "#FAFAFA"
```

3. **Deploy tr√™n streamlit.io**
   - Truy c·∫≠p https://share.streamlit.io
   - K·∫øt n·ªëi GitHub repo
   - C·∫•u h√¨nh secrets (API Key)
   - Deploy!

### 9.3 C·∫•u H√¨nh Secrets

Tr√™n Streamlit Cloud, th√™m secrets trong dashboard:

```toml
# .streamlit/secrets.toml (local) ho·∫∑c Dashboard (cloud)
GROQ_API_KEY = "gsk_xxxxxxxxxxxxxxxxxxxxxxxx"
```

Truy c·∫≠p trong code:
```python
import streamlit as st

api_key = st.secrets["GROQ_API_KEY"]
```

---

## üìö T·ªïng K·∫øt

### Quy Tr√¨nh X√¢y D·ª±ng T√≥m T·∫Øt

1. **Thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng** ‚Üí Python venv + requirements.txt
2. **Config** ‚Üí API key, settings
3. **Utils** ‚Üí Logic x·ª≠ l√Ω (summarization, quiz_generator)
4. **Components** ‚Üí UI modules (chatbot, quiz_display, sidebar)
5. **App.py** ‚Üí ƒêi·ªÅu ph·ªëi v√† k·∫øt n·ªëi t·∫•t c·∫£
6. **Testing** ‚Üí Ch·∫°y local, debug
7. **Deploy** ‚Üí Streamlit Cloud

### K·ªπ Thu·∫≠t Quan Tr·ªçng

- **Prompt Engineering**: Vi·∫øt prompt r√µ r√†ng, c√≥ c·∫•u tr√∫c
- **Error Handling**: X·ª≠ l√Ω m·ªçi tr∆∞·ªùng h·ª£p l·ªói
- **Fallback Models**: Backup khi model ch√≠nh fail
- **Caching**: T·ªëi ∆∞u API calls v√† t·ªëc ƒë·ªô
- **Session State**: Duy tr√¨ tr·∫°ng th√°i ·ª©ng d·ª•ng

### M·ªü R·ªông Trong T∆∞∆°ng Lai

- Export PDF cho quiz v√† summary
- H·ªó tr·ª£ playlist YouTube
- User authentication
- L∆∞u l·ªãch s·ª≠ h·ªçc t·∫≠p
- Mobile app

---

**T√°c gi·∫£:** AI YouTube Summarizer Team  
**Phi√™n b·∫£n:** 1.0.0  
**Ng√†y c·∫≠p nh·∫≠t:** Th√°ng 2, 2026

---

*N·∫øu c√≥ c√¢u h·ªèi, vui l√≤ng t·∫°o Issue tr√™n GitHub ho·∫∑c li√™n h·ªá qua email!* üöÄ
