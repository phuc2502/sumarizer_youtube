# chatbot.py
# Enhanced Chatbot vá»›i context-aware vÃ  gá»£i Ã½ cÃ¢u há»i

import os
import time
import streamlit as st
from groq import Groq

# System prompt nÃ¢ng cao cho chatbot
CHATBOT_SYSTEM_PROMPT = """Báº¡n lÃ  trá»£ lÃ½ AI thÃ´ng minh, thÃ¢n thiá»‡n vÃ  há»¯u Ã­ch. 
Báº¡n cÃ³ nhiá»‡m vá»¥ giÃºp ngÆ°á»i dÃ¹ng hiá»ƒu sÃ¢u hÆ¡n vá» ná»™i dung video YouTube.

NGUYÃŠN Táº®C:
1. Tráº£ lá»i dá»±a trÃªn ná»™i dung video Ä‘Ã£ Ä‘Æ°á»£c tÃ³m táº¯t
2. Náº¿u cÃ¢u há»i náº±m ngoÃ i ná»™i dung video, thÃ´ng bÃ¡o lá»‹ch sá»± vÃ  cá»‘ gáº¯ng liÃªn há»‡ vá»›i chá»§ Ä‘á»
3. Sá»­ dá»¥ng ngÃ´n ngá»¯ dá»… hiá»ƒu, thÃ¢n thiá»‡n
4. CÃ³ thá»ƒ Ä‘Æ°a ra vÃ­ dá»¥ minh há»a khi cáº§n
5. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t (trá»« khi Ä‘Æ°á»£c yÃªu cáº§u khÃ¡c)

Ná»˜I DUNG VIDEO ÄÃƒ TÃ“M Táº®T:
{summary}
"""

# Gá»£i Ã½ cÃ¢u há»i máº«u
SUGGESTED_QUESTIONS = [
    "ğŸ“ TÃ³m táº¯t láº¡i ngáº¯n gá»n trong 3 cÃ¢u",
    "ğŸ”‘ Nhá»¯ng Ä‘iá»ƒm chÃ­nh quan trá»ng nháº¥t lÃ  gÃ¬?",
    "ğŸ’¡ Giáº£i thÃ­ch chi tiáº¿t hÆ¡n vá» chá»§ Ä‘á» nÃ y",
    "ğŸ“š CÃ³ thá»ƒ Ã¡p dá»¥ng kiáº¿n thá»©c nÃ y nhÆ° tháº¿ nÃ o?",
    "â“ CÃ²n Ä‘iá»u gÃ¬ tÃ´i cáº§n biáº¿t thÃªm khÃ´ng?",
]

# Initialize show_prompt if not already done
if 'show_prompt' not in st.session_state:
    st.session_state.show_prompt = False

if 'chat_messages' not in st.session_state:
    st.session_state.chat_messages = []


def initialize_client(api_key):
    """Initialize the Groq client with the provided API key."""
    return Groq(api_key=api_key)


def generate_chatbot_response(client, user_question, use_context=True):
    """
    Generate a response from the chatbot based on the cached summary and user question.
    
    Args:
        client: Groq client
        user_question: CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
        use_context: CÃ³ sá»­ dá»¥ng context tá»« summary khÃ´ng
    
    Returns:
        str: CÃ¢u tráº£ lá»i tá»« AI
    """
    # Retrieve summary from session state
    summary = st.session_state.get('follow_up_summary', "")
    
    if not summary and use_context:
        return "âš ï¸ ChÆ°a cÃ³ báº£n tÃ³m táº¯t video. Vui lÃ²ng táº¡o báº£n tÃ³m táº¯t trÆ°á»›c khi trÃ² chuyá»‡n!"

    # Build conversation history
    messages = []
    
    # System message vá»›i context
    if use_context and summary:
        system_content = CHATBOT_SYSTEM_PROMPT.format(summary=summary)
        messages.append({"role": "system", "content": system_content})
    
    # Add conversation history (last 10 messages to avoid token limit)
    history = st.session_state.get('chat_messages', [])[-10:]
    for msg in history:
        messages.append({"role": msg["role"], "content": msg["content"]})
    
    # Add current question
    messages.append({"role": "user", "content": user_question})

    try:
        # Generate response using the client
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages,
            temperature=0.7,
            max_tokens=1500,
            top_p=1,
            stream=True,
        )

        # Accumulate response chunks
        response = ""
        for chunk in completion:
            if chunk.choices[0].delta.content:
                response += chunk.choices[0].delta.content

        return response
        
    except Exception as e:
        error_msg = str(e)
        if "rate_limit" in error_msg.lower():
            return "âš ï¸ ÄÃ£ vÆ°á»£t quÃ¡ giá»›i háº¡n API. Vui lÃ²ng Ä‘á»£i vÃ i phÃºt vÃ  thá»­ láº¡i."
        elif "invalid_api_key" in error_msg.lower():
            return "âŒ API Key khÃ´ng há»£p lá»‡. Vui lÃ²ng kiá»ƒm tra láº¡i."
        else:
            return f"âŒ Lá»—i: {error_msg}"


@st.fragment
def display_download_button(content, file_name):
    """Display a download button for the assistant's response."""
    if st.download_button(
        label="ğŸ’¾ LÆ°u",
        data=content,
        file_name=file_name,
        mime="text/plain",
        icon=":material/download:"
    ):
        st.toast("ÄÃ£ lÆ°u thÃ nh cÃ´ng!", icon="âœ…")


def display_typing_simulation(text, delay=0.005):
    """Simulate typing effect for displaying responses."""
    response_placeholder = st.empty()
    displayed_text = ""
    for char in text:
        displayed_text += char
        response_placeholder.markdown(displayed_text + "â–Œ")
        time.sleep(delay)
    response_placeholder.markdown(displayed_text)
    return displayed_text


def display_suggested_questions():
    """Hiá»ƒn thá»‹ cÃ¡c cÃ¢u há»i gá»£i Ã½."""
    st.markdown("##### ğŸ’¡ CÃ¢u há»i gá»£i Ã½:")
    
    cols = st.columns(2)
    for i, question in enumerate(SUGGESTED_QUESTIONS):
        with cols[i % 2]:
            if st.button(question, key=f"suggest_{i}", use_container_width=True):
                return question.split(" ", 1)[1]  # Remove emoji prefix
    return None


def display_chat_enhanced(client):
    """
    Display the enhanced chat interface with better UX.
    """
    st.markdown("### ğŸ’¬ TrÃ² Chuyá»‡n Vá» Video")
    
    # Kiá»ƒm tra Ä‘Ã£ cÃ³ summary chÆ°a
    if "follow_up_summary" not in st.session_state or not st.session_state.follow_up_summary:
        st.warning("âš ï¸ Vui lÃ²ng táº¡o báº£n tÃ³m táº¯t video trÆ°á»›c khi trÃ² chuyá»‡n!")
        st.info("ğŸ‘‰ Quay láº¡i tab **TÃ³m táº¯t** vÃ  nháº¥n **Get Detailed Notes**")
        return
    
    # Initialize chat messages
    if 'chat_messages' not in st.session_state:
        st.session_state.chat_messages = []
    
    # Suggested questions (only show if no messages yet)
    if len(st.session_state.chat_messages) == 0:
        suggested = display_suggested_questions()
        if suggested:
            process_user_message(client, suggested)
            st.rerun()
    
    # Chat container
    chat_container = st.container(height=400)
    
    with chat_container:
        # Display chat history
        for message in st.session_state.chat_messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
    
    # Chat input
    user_input = st.chat_input("ğŸ’¬ Nháº­p cÃ¢u há»i cá»§a báº¡n vá» video...")
    
    if user_input:
        process_user_message(client, user_input)
        st.rerun()
    
    # Action buttons
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ—‘ï¸ XÃ³a lá»‹ch sá»­ chat", use_container_width=True):
            st.session_state.chat_messages = []
            st.rerun()
    
    with col2:
        if st.session_state.chat_messages:
            # Export chat history
            chat_export = "\n\n".join([
                f"{'ğŸ‘¤ Báº¡n' if m['role'] == 'user' else 'ğŸ¤– AI'}: {m['content']}"
                for m in st.session_state.chat_messages
            ])
            st.download_button(
                "ğŸ“¥ Táº£i lá»‹ch sá»­ chat",
                data=chat_export,
                file_name="chat_history.txt",
                mime="text/plain",
                use_container_width=True
            )


def process_user_message(client, user_message: str):
    """
    Xá»­ lÃ½ tin nháº¯n cá»§a ngÆ°á»i dÃ¹ng vÃ  táº¡o response.
    """
    # Add user message
    st.session_state.chat_messages.append({
        "role": "user",
        "content": user_message
    })
    
    # Generate response
    with st.spinner("ğŸ¤” Äang suy nghÄ©..."):
        response = generate_chatbot_response(client, user_message)
    
    # Add assistant message
    st.session_state.chat_messages.append({
        "role": "assistant", 
        "content": response
    })


# Legacy function for backward compatibility
def display_chat(client):
    """Display the chat interface (legacy support)."""
    display_chat_enhanced(client)
